{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754d20bb",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b13c2b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10839384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./data-challenge-kernel-methods-2022-2023/test_data.pkl', 'rb') as f:\n",
    "    challenge_data = pickle.load(f)\n",
    "    \n",
    "with open('./data-challenge-kernel-methods-2022-2023/training_data.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "with open('./data-challenge-kernel-methods-2022-2023/training_labels.pkl', 'rb') as f:\n",
    "    train_label = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e9353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67712b0b-135f-4073-bc9b-417a57258407",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Implement RWK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bafc937-240c-4585-b003-c71be0325603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "class ProductGraph:\n",
    "    '''\n",
    "    Direct product graph. \n",
    "    Functions in this version take adjacency matrices and dictionaries with labels objects.\n",
    "    \n",
    "    Contains two functions, one for labeled nodes and one for unlabeled nodes.\n",
    "    They allow to return a graph object or the adjacency matrix.\n",
    "    It's the version needed for the random walk kernel.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def labeled_nodes(self,G1, G2, return_nx = False):\n",
    "        '''\n",
    "        Direct product graph (aka Tensor Product of Graph).\n",
    "        Assumes graphs have attribute 'labels' for each node.\n",
    "        Also assumes nodes in the graphs are numbered starting from 0.\n",
    "        These properties appear to be true in our dataset.\n",
    "        Does not take into account labeled edges.\n",
    "        \n",
    "        Will return only adjacency matrix of the product by default. \n",
    "        \n",
    "        If return_nx is True, a networkx object with labeled nodes will be returned\n",
    "        \n",
    "        _Parameters_\n",
    "        :param adj_G1, adj_G2: adjacency matrices \n",
    "        :param labels_1,  labels_2: dictionaries with the numbers of the nodes and the labels \n",
    "        '''\n",
    "\n",
    "        #obtain adjacency matrix and dictionaries with labels from graphs\n",
    "        adj_G1 = nx.adjacency_matrix(G1) #this outputs scipy sparse matrix \n",
    "        labels_1 = nx.get_node_attributes(G1, 'labels')\n",
    "\n",
    "        adj_G2 = nx.adjacency_matrix(G2) #this outputs scipy sparse matrix \n",
    "        labels_2 = nx.get_node_attributes(G2, 'labels')\n",
    "            \n",
    "        n = adj_G1.shape[0]\n",
    "\n",
    "        m = adj_G2.shape[0]\n",
    "\n",
    "        adj_prod = scipy.sparse.kron(adj_G1,adj_G2,format='csr') #adjacency matrix of the simple product graph\n",
    "         # create graph from adjacency matrix\n",
    "\n",
    "        k = adj_prod.shape[0]\n",
    "        \n",
    "        if k==0:\n",
    "            return np.empty(0) \n",
    "        if return_nx:\n",
    "            #Here we want to put the label in the product graph, so we take advantage of\n",
    "            #the structure of the nx graph object\n",
    "            prodG = nx.from_scipy_sparse_array(adj_prod)\n",
    "            for i in range(1, k+1):\n",
    "                #Corresponding nodes in G1 and G2 to node i in the product\n",
    "                node_1 =  (i-(i%m))/m +1 if i%m!=0 else (i-(i%m))/m \n",
    "                node_2 = i%m if i%m!=0 else m\n",
    "\n",
    "                #Remove node in product if labels are different, set label otherwise\n",
    "                if labels_1[node_1-1]!=labels_2[node_2-1]:\n",
    "                    prodG.remove_node(i-1)\n",
    "                else:\n",
    "                    nx.set_node_attributes(prodG, {i-1:labels_1[node_1-1]}, 'labels')\n",
    "            return prodG\n",
    "        \n",
    "        else: \n",
    "            #We try to work only with matrices to work more efficiently.\n",
    "            # However going from matrix to sparse and/or viceversa might be costly\n",
    "            \n",
    "            #I checked and this is faster than dealing with the networkx graph and the retreiving its adjacency matrix\n",
    "            \n",
    "            nodes_to_remove =[]\n",
    "            for i in range(1, k+1):\n",
    "                #Corresponding nodes in G1 and G2 to node i in the product\n",
    "                node_1 =  (i-(i%m))/m +1 if i%m!=0 else (i-(i%m))/m \n",
    "                node_2 = i%m if i%m!=0 else m\n",
    "\n",
    "                #Remove node in product if labels are different, set label otherwise\n",
    "                if labels_1[node_1-1]!=labels_2[node_2-1]:\n",
    "                    nodes_to_remove.append(i-1)\n",
    "                    \n",
    "            adj_prod = adj_prod.toarray()\n",
    "            adj_prod=np.delete(arr = adj_prod, obj = nodes_to_remove,axis = 0)\n",
    "            adj_prod=np.delete(arr = adj_prod, obj = nodes_to_remove,axis = 1)\n",
    "            \n",
    "            return adj_prod\n",
    "\n",
    "            \n",
    "    def unlabeled(self,G1,G2,return_nx = False):\n",
    "        '''\n",
    "        Direct product graph (aka Tensor Product of Graph).\n",
    "        \n",
    "        Here we do not take into account the labels of the graph.\n",
    "        \n",
    "        It returns the adjacency matrix of the product.\n",
    "        ! It is a scipy sparse matrix\n",
    "        '''\n",
    "\n",
    "        #obtain adjacency matrix from graphs\n",
    "        adj_G1 = nx.adjacency_matrix(G1) #this outputs scipy sparse matrix \n",
    "        adj_G2 = nx.adjacency_matrix(G2) #this outputs scipy sparse matrix \n",
    "  \n",
    "        adj_prod = scipy.sparse.kron(adj_G1,adj_G2) #adjacency matrix of the simple product graph\n",
    "        \n",
    "        if return_nx:\n",
    "            return nx.from_scipy_sparse_array(adj_prod)\n",
    "        else:\n",
    "            return adj_prod\n",
    "        \n",
    "        \n",
    "    def labeled_edges(self,G1, G2, return_nx = False):\n",
    "        '''\n",
    "        Direct product graph (aka Tensor Product of Graph) taking into account labeled\n",
    "        nodes and edges.\n",
    "        Assumes graphs have attribute 'labels' for each node and for each edge.\n",
    "        Also assumes nodes in the graphs are numbered starting from 0.\n",
    "        These properties appear to be true in our dataset.\n",
    "\n",
    "        Will return only adjacency matrix of the product by default. \n",
    "        \n",
    "        If return_nx is True, a networkx object with labeled nodes will be returned\n",
    "        \n",
    "        _Parameters_\n",
    "        :param adj_G1, adj_G2: adjacency matrices \n",
    "        :param labels_1,  labels_2: dictionaries with the numbers of the nodes and the labels \n",
    "        '''\n",
    "\n",
    "        #obtain adjacency matrix and dictionaries with labels from graphs\n",
    "        adj_G1 = nx.adjacency_matrix(G1)\n",
    "        adj_G2 = nx.adjacency_matrix(G2)\n",
    "        node_labels_1 = nx.get_node_attributes(G1, 'labels')\n",
    "        node_labels_2 = nx.get_node_attributes(G2, 'labels')\n",
    "        \n",
    "        n = adj_G1.shape[0]\n",
    "\n",
    "        m = adj_G2.shape[0]\n",
    "\n",
    "        \n",
    "        adj_prod = scipy.sparse.kron(adj_G1,adj_G2,format='csr')\n",
    "        \n",
    "        # TODO We have to deal with labeled nodes returning 0\n",
    "                \n",
    "        if return_nx:\n",
    "            prod =  self.labeled_nodes(G1, G2, return_nx = True)\n",
    "\n",
    "            # TODO We have to deal with labeled nodes returning 0\n",
    "            \n",
    "            to_remove = []\n",
    "\n",
    "            for edge in prod.edges(data=True):\n",
    "                #Corresponding nodes in G1 and G2 to node i in the product\n",
    "                start = edge[0]+1\n",
    "                end = edge[1]+1\n",
    "                start_1 =  (start-(start%m))/m +1 if start%m!=0 else (start-(start%m))/m \n",
    "                start_2 = start%m if start%m!=0 else m\n",
    "                end_1 =  (end-(end%m))/m +1 if end%m!=0 else (end-(end%m))/m \n",
    "                end_2 = end%m if end%m!=0 else m\n",
    "\n",
    "                #print('p', start,end)\n",
    "                #print('G1', start_1, end_1)\n",
    "                #print('G2', start_2, end_2)\n",
    "\n",
    "                label_1 = G1.get_edge_data(start_1-1, end_1-1)['labels']\n",
    "                label_2 = G2.get_edge_data(start_2-1, end_2-1)['labels']\n",
    "\n",
    "                #Remove node in product if labels are different, set label otherwise\n",
    "                if label_1!=label_2:\n",
    "                    to_remove.append((start-1, end-1))\n",
    "                else:\n",
    "                    nx.set_edge_attributes(prod, {(start-1, end-1):label_1}, 'labels')\n",
    "\n",
    "            prod.remove_edges_from(to_remove)\n",
    "            #prod.remove_nodes_from(list(nx.isolates(prod)))\n",
    "\n",
    "            return prod\n",
    "\n",
    "        else: \n",
    "            edges_to_remove = []\n",
    "            nodes_to_remove =[]\n",
    "\n",
    "            cx = adj_prod.tocoo()\n",
    "            \n",
    "            for start,end in zip(cx.row, cx.col):\n",
    "                start +=1\n",
    "                end +=1\n",
    "                start_1 =  (start-(start%m))/m +1 if start%m!=0 else (start-(start%m))/m \n",
    "                start_2 = start%m if start%m!=0 else m\n",
    "                end_1 =  (end-(end%m))/m +1 if end%m!=0 else (end-(end%m))/m \n",
    "                end_2 = end%m if end%m!=0 else m\n",
    "\n",
    "                label_1 = G1.get_edge_data(start_1-1, end_1-1)['labels']\n",
    "                label_2 = G2.get_edge_data(start_2-1, end_2-1)['labels']\n",
    "\n",
    "                #Remove node in product if labels are different, set label otherwise\n",
    "                if label_1!=label_2:\n",
    "                    edges_to_remove.append((start-1, end-1))\n",
    "\n",
    "                if node_labels_1[start_1-1]!=node_labels_2[start_2-1]:\n",
    "                    nodes_to_remove.append(start-1)\n",
    "\n",
    "                if node_labels_1[end_1-1]!=node_labels_2[end_2-1]:\n",
    "                    nodes_to_remove.append(end-1)\n",
    "\n",
    "            adj_prod = adj_prod.toarray()\n",
    "\n",
    "            for edge in edges_to_remove:\n",
    "                adj_prod[edge[0],edge[1]]=0\n",
    "                adj_prod[edge[1],edge[0]]=0\n",
    "\n",
    "            adj_prod=np.delete(arr = adj_prod, obj = nodes_to_remove,axis = 0)\n",
    "            adj_prod=np.delete(arr = adj_prod, obj = nodes_to_remove,axis = 1)\n",
    "\n",
    "            return adj_prod\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "935b3f89-b37e-432c-bd60-32df7b2378f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import cg\n",
    "from scipy.sparse.linalg import LinearOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca6e48-06be-4435-a473-91df0bdd149b",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will do an implementation of the random walk kernel using Conjugate Gradient Method proposed by [Graph Kernels 2010, Vishwanathan et al]\n",
    "We solve (I-lambda*A)X = p using the cg method from scipy.sparse.linalg, but using the formula from the paper to compute Ax.\n",
    "With their notation, letting A be de adjacency matrix of the product graph, and $A_1$ and $A_2$ of the original graphs, it follows\n",
    "\n",
    "$$\n",
    "(I-\\lambda A)x = Ix-\\lambda vec(A_2  X  A_1^T)\n",
    "$$\n",
    "\n",
    "where, if B is a matrix of size $n\\times m$ $vec(B)$ is the vector of size $nm$ resulting from stacking itss columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab2662f0-3e0f-4a4b-8e94-fa2e6d5bd265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Labeled_Random_Walk_Kernel:\n",
    "    def __init__(self, weight = 0.1, method = 'direct'):\n",
    "        self.weight = weight\n",
    "        self.method = method\n",
    "    \n",
    "    def kernel_simple(self,G1,G2):\n",
    "        '''\n",
    "        Computes kernel function for 2 graphs\n",
    "        '''\n",
    "        \n",
    "        if self.method == 'direct': \n",
    "\n",
    "            prod = ProductGraph().labeled_nodes(G1,G2, return_nx = False)\n",
    "\n",
    "            # I ckecked, and converting to sparse matrix and then using sparse solver is faster than keeping it as np.ndarray and using np.linalg solver\n",
    "            prod = scipy.sparse.csr_matrix(prod) \n",
    "\n",
    "            nm = prod.shape[0] #Number of nodes in product graph\n",
    "\n",
    "            if nm!=0: \n",
    "                output= np.ones(nm).T@scipy.sparse.linalg.spsolve(scipy.sparse.eye(nm)-self.weight*prod,np.ones(nm)) #direct inverse\n",
    "            else:\n",
    "                output=0\n",
    "        elif self.method == 'cg':\n",
    "            #To Be Implemented\n",
    "            \n",
    "            output=0\n",
    "\n",
    "        #Can be normalized using the following line instead\n",
    "        #if nm!=0: output= (1/nm)*np.ones(nm).T@np.linalg.solve(np.eye(nm)-self.weight*prod.toarray(),np.ones(nm)) #direct inverse\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def kernel_matrix (self, G):\n",
    "        '''\n",
    "        Computes kernel matrix for a list of graphs.\n",
    "        \n",
    "        '''\n",
    "        n = len(G)\n",
    "        \n",
    "        K = np.zeros((n,n))\n",
    "        \n",
    "        for i in tqdm(range(n)):\n",
    "            for j in range(i,n):\n",
    "                K[i][j] = self.kernel_simple(G[i], G[j])\n",
    "                if i!=j:\n",
    "                    K[j][i]= K[i][j]\n",
    "   \n",
    "        return K\n",
    "\n",
    "    def kernel(self,G1,G2):\n",
    "        '''\n",
    "        Computes pairwise kernel comparisons between two lists of graphs.\n",
    "        '''\n",
    "        n = len(G1)\n",
    "        m = len(G2)\n",
    "        K = np.zeros((n,m))\n",
    "        \n",
    "        \n",
    "        for i in tqdm(range(n)):\n",
    "            for j in range(m):\n",
    "                K[i][j] = self.kernel_simple(G1[i], G2[j])\n",
    "                    \n",
    "        return K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd040c8-c5cf-49c5-a379-0a5d6d0045ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Implementing Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c67eb80b-c365-4548-a064-ea5734d6f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import solvers\n",
    "from cvxopt import matrix\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46f2f7a1-7d06-4699-b5da-71df81a898a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVC:\n",
    "    '''\n",
    "    Suport vector machine classifier from homework 2 with a few modifications so it works with the kernel class we have defined for the\n",
    "    random walk kernel. \n",
    "    We change the optimizer to use one specifically for quadratic programming convex problems from the cvxopt library.\n",
    "    I also added a precomputed_K parameter, so if you run the fit function for some data, before rerruning for, for example a\n",
    "    different value of C, you can save the kernel matrix that is saved in the attribure K, and save time. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, C, kernel, precomputed_K = np.array([]), epsilon = 1e-5):\n",
    "        self.type = 'non-linear'\n",
    "        self.C = C                               \n",
    "        self.kernel = kernel        \n",
    "        self.alpha = None\n",
    "        self.support = None\n",
    "        self.epsilon = epsilon\n",
    "        self.norm_f = None\n",
    "        self.support_coefs = None\n",
    "        self.K = precomputed_K\n",
    "       \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "       #### You might define here any variable needed for the rest of the code\n",
    "        N = len(y)\n",
    "        \n",
    "        if self.K.shape[0]==0:\n",
    "            self.K = self.kernel.kernel_matrix(X)\n",
    "        \n",
    "        diag_y = np.diag(y)\n",
    "        P = diag_y.T @ self.K @ diag_y\n",
    "        q = - np.ones(N).astype(np.double)\n",
    "        G = np.vstack((np.identity(N),  -np.identity(N))).astype(np.double)\n",
    "        h = np.hstack((self.C*np.ones((N)),np.zeros((N)))).astype(np.double)\n",
    "        A = y.reshape(1,N).astype(np.double)\n",
    "        b = np.zeros((1,1), np.double)\n",
    "        \n",
    "        optRes = solvers.qp(matrix(P), matrix(q), matrix(G), matrix(h), matrix(A), matrix(b))\n",
    "        \n",
    "        self.alpha = np.asarray(optRes['x']).reshape(N)\n",
    "        \n",
    "        \n",
    "        print('alpha', self.alpha)\n",
    "        ## Assign the required attributes\n",
    "        \n",
    "   \n",
    "        #'''------------------- A matrix with each row corresponding to a point that falls on the margin ------------------''       \n",
    "        #Points that lay in te margin are also those s.t. 0<alpha_i<C\n",
    "        indices_on_margin = np.asarray((self.alpha>self.epsilon) & (self.alpha<self.C)).nonzero()[0]\n",
    "        self.margin_points =  [X[l] for l in indices_on_margin]\n",
    "        \n",
    "         #''' -----------------offset of the classifier------------------ '''\n",
    "        #Obtain supporting vectors and their corresponding coefficient for f\n",
    "        sv_indices = np.asarray((self.alpha>self.epsilon)).nonzero()[0]\n",
    "        self.support = [X[l] for l in sv_indices]\n",
    "        self.support_coefs = np.multiply(self.alpha[sv_indices], y[sv_indices])\n",
    "    \n",
    "                         \n",
    "        #Compute b as the average of b obtained by points in margin                 \n",
    "        self.b = np.mean((y[indices_on_margin]-self.separating_function_K(indices_on_margin, sv_indices)))\n",
    "        \n",
    "        \n",
    "        # '''------------------------RKHS norm of the function f ------------------------------'''          \n",
    "        #self.norm_f = (self.alpha.T@ self.K)@self.alpha\n",
    "\n",
    "        \n",
    "    def separating_function_K(self,indices_on_margin, sv_indices):\n",
    "        '''\n",
    "        Computes the separating function in the specific points needed to compute the offset b.\n",
    "        It uses the kernel matrix on the data instead od recomputing the kernel in these points.\n",
    "        \n",
    "        '''\n",
    "        print('Computing Separating Function on margin')\n",
    "        K = np.asarray([[self.K[i][j] for i in list(sv_indices)] for j in list(indices_on_margin)])\n",
    "    \n",
    "        return self.support_coefs @ K\n",
    "    \n",
    "    ### Implementation of the separting function $f$ \n",
    "    def separating_function(self,x):\n",
    "        # Input : matrix x of shape N data points times d dimension\n",
    "        # Output: vector of size N\n",
    "\n",
    "        K = self.kernel.kernel(self.support,x)\n",
    "        return self.support_coefs @ K \n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict y values in {-1, 1} \"\"\"\n",
    "        d = self.separating_function(X)\n",
    "        #print('d',d)\n",
    "        return np.sign(d+self.b)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e64d9-8e2f-4579-bb70-bffd2d03da80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Create Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd0a9e66-e931-46ae-8d67-b32033a0d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./RWK_Labeled_4200.pkl', 'rb') as f: \n",
    "        K_train4200_label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b3f8046-7b7a-4327-8a0e-2007ce71f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.asarray(y_train==1).nonzero()[0]\n",
    "alll = np.asarray(range(4200))\n",
    "arr0 = np.delete(alll, arr1)\n",
    "\n",
    "# Original train dataset has a 10% of elements from category 1. We create a dataset with 20% of category 1.\n",
    "balanced = np.append(arr1, arr0[:810])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d03772-98ce-4436-b40e-822959edc2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced = [X_train[l] for l in balanced]\n",
    "y_balanced = y_train[balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e7e76e4-dab8-44bf-bf95-49604c08a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_balanced = K_train4200_label[balanced,:]\n",
    "K_balanced = K_balanced[:, balanced]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62966fd9-6891-4bdf-b97e-183b2f3c7186",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting. Current Time = 18:10:49\n",
      "rank A 1\n",
      "Rank([P; A; G])  1215\n",
      "Begin optimizing\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.7708e+06 -6.8706e+08  2e+09  1e+00  2e-08\n",
      " 1:  7.5646e+06 -3.5677e+08  5e+08  2e-01  2e-08\n",
      " 2:  5.1246e+06 -1.0139e+08  1e+08  3e-02  3e-08\n",
      " 3:  1.9853e+06 -3.2220e+07  4e+07  9e-03  2e-08\n",
      " 4:  4.3180e+05 -8.7915e+06  9e+06  8e-04  2e-08\n",
      " 5:  5.5251e+04 -2.6229e+06  3e+06  2e-04  2e-08\n",
      " 6:  9.4701e+03 -2.3946e+06  2e+06  1e-04  2e-08\n",
      " 7: -1.0126e+05 -7.0637e+05  6e+05  2e-05  2e-08\n",
      " 8: -1.4527e+05 -4.1817e+05  3e+05  6e-06  2e-08\n",
      " 9: -1.6618e+05 -3.2764e+05  2e+05  3e-06  2e-08\n",
      "10: -1.8344e+05 -2.6198e+05  8e+04  1e-06  2e-08\n",
      "11: -1.9134e+05 -2.3647e+05  5e+04  5e-07  2e-08\n",
      "12: -1.9695e+05 -2.1864e+05  2e+04  1e-07  2e-08\n",
      "13: -2.0079e+05 -2.0876e+05  8e+03  3e-08  3e-08\n",
      "14: -2.0257e+05 -2.0448e+05  2e+03  2e-11  3e-08\n",
      "15: -2.0317e+05 -2.0344e+05  3e+02  2e-11  2e-08\n",
      "16: -2.0326e+05 -2.0330e+05  4e+01  6e-11  2e-08\n",
      "17: -2.0327e+05 -2.0328e+05  3e+00  1e-10  3e-08\n",
      "18: -2.0327e+05 -2.0327e+05  5e-02  5e-12  3e-08\n",
      "Optimal solution found.\n",
      "alpha [2.09510796e-05 1.72204166e-05 6.55912713e+02 ... 1.35826339e+02\n",
      " 3.05218184e-06 1.01341512e-05]\n",
      "Computing Separating Function on margin\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting. Current Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "# Initiating classifier and fitting training data\n",
    "svc = KernelSVC(C = 700, precomputed_K =  K_balanced, kernel = Labeled_Random_Walk_Kernel(method='direct'))\n",
    "svc.fit(X_balanced, 2*y_balanced-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c5b1dc-3694-4f48-8ae1-540a9cbd65e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4.  Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d9fc742-13fa-4258-a6f6-cfd3f1b5ff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/976 [00:00<?, ?it/s]/var/folders/k0/xshtxbl53md8lxz0q286gwg40000gn/T/ipykernel_4487/365156290.py:36: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj_G1 = nx.adjacency_matrix(G1) #this outputs scipy sparse matrix\n",
      "/var/folders/k0/xshtxbl53md8lxz0q286gwg40000gn/T/ipykernel_4487/365156290.py:39: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj_G2 = nx.adjacency_matrix(G2) #this outputs scipy sparse matrix\n",
      "  0%|          | 3/976 [00:11<1:00:41,  3.74s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k0/xshtxbl53md8lxz0q286gwg40000gn/T/ipykernel_4487/1308223973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchallenge_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_submission\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k0/xshtxbl53md8lxz0q286gwg40000gn/T/ipykernel_4487/1394421946.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;34m\"\"\" Predict y values in {-1, 1} \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparating_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m#print('d',d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k0/xshtxbl53md8lxz0q286gwg40000gn/T/ipykernel_4487/1394421946.py\u001b[0m in \u001b[0;36mseparating_function\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Output: vector of size N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_coefs\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k0/xshtxbl53md8lxz0q286gwg40000gn/T/ipykernel_4487/2965202567.py\u001b[0m in \u001b[0;36mkernel\u001b[0;34m(self, G1, G2)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k0/xshtxbl53md8lxz0q286gwg40000gn/T/ipykernel_4487/2965202567.py\u001b[0m in \u001b[0;36mkernel_simple\u001b[0;34m(self, G1, G2)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'direct'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProductGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeled_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_nx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# I ckecked, and converting to sparse matrix and then using sparse solver is faster than keeping it as np.ndarray and using np.linalg solver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/k0/xshtxbl53md8lxz0q286gwg40000gn/T/ipykernel_4487/365156290.py\u001b[0m in \u001b[0;36mlabeled_nodes\u001b[0;34m(self, G1, G2, return_nx)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlabels_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0madj_G2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this outputs scipy sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mlabels_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/linalg/graphmatrix.py\u001b[0m in \u001b[0;36madjacency_matrix\u001b[0;34m(G, nodelist, dtype, weight)\u001b[0m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# TODO: Change to `to_scipy_sparse_array` for networkx 3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_scipy_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodelist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/convert_matrix.py\u001b[0m in \u001b[0;36mto_scipy_sparse_matrix\u001b[0;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[0;32m-> 1021\u001b[0;31m     A = to_scipy_sparse_array(\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodelist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/networkx/convert_matrix.py\u001b[0m in \u001b[0;36mto_scipy_sparse_array\u001b[0;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoo_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unknown sparse matrix format: {format}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;31m# Forward the copy kwarg, if it's accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    405\u001b[0m                       indptr, indices, data)\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_csr_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36mcheck_format\u001b[0;34m(self, full_check)\u001b[0m\n\u001b[1;32m    179\u001b[0m                              \"the size of index and data arrays\")\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfull_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36mprune\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prune_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prune_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36mnnz\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m                                   self.__class__.__name__)\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"Number of stored values, including explicit zeros.\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_submission = svc.predict(challenge_data)\n",
    "\n",
    "y_df = [1 if y==1 else 0 for y in y_submission]\n",
    "\n",
    "import pandas as pd\n",
    "Yte = {'Predicted' : y_df} \n",
    "dataframe = pd.DataFrame(Yte) \n",
    "dataframe.index += 1 \n",
    "\n",
    "dataframe.to_csv('test_pred.csv',index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307474d-3a80-480b-aa93-fdfd95ba3772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
